<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Solutions</title>

<script src="solutions_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="solutions_files/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="solutions_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="solutions_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="solutions_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="solutions_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="solutions_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="solutions_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="solutions_files/navigation-1.1/tabsets.js"></script>
<script src="solutions_files/navigation-1.1/codefolding.js"></script>
<link href="solutions_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="solutions_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">DiD Notes</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="intro.html">Introduction</a>
</li>
<li>
  <a href="problems.html">Problems</a>
</li>
<li>
  <a href="solutions.html">Solutions</a>
</li>
<li>
  <a href="definitions.html">Definitions</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Solutions</h1>

</div>


<p>Multiple contributions offer various ways to deal with the potential <a href="problems.html"><strong>problems</strong></a>. We found <strong>Imai, Kim and Wang 2022</strong> and <strong>Wooldridge 2021</strong> particularly useful.</p>
<div id="ImaiKimWang" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Imai, Kim and Wang 2022</h1>
<p><a href="https://doi.org/10.1111/ajps.12685">“Matching methods for Causal Inference with Time-Series Cross-Sectional Data” by Imai, K., Kim, I.S. and Wang, E.H. (2022)</a></p>
<p>R-package: <a href="https://github.com/insongkim/PanelMatch">PanelMatch()</a>.</p>
<p><span class="math inline">\(~\)</span></p>
<div id="the-problem-it-solves" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> The problem it solves</h2>
<p>Most matching methods are not fit for Time-Series Cross-Sectional (TSCS) data. The few solutions that exist assume <a href="definitions.html"><strong>staggered adoption</strong></a>. They create a matched DiD-application for TSCS-data without this assumption.</p>
<p>They address staggered adoption both in the sense that units are treated at unequal T, but also that there is a Average Causal effect of Reversal (ART), so that units jump back and forth in being treated. To our knowledge, this is the only solution that seamlessly integrates both of these effects.</p>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="the-way-it-solves-it" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> The way it solves it</h2>
<p>Their proposed solution is best understood as a three-stage process. In stage 1 we construct, for each treated unit, a matched set of control units that share identical treatment status over an adjustable time period <a href="definitions.html"><strong>L</strong></a>. In stage 2 we refine these matched sets of units by balancing over observed, time-varying confounders. In stage 3 we execute the DiD-estimator.</p>
<pre class="r"><code>library(tidyverse);library(PanelMatch);library(fixest);library(did2s);library(did)

data(dem) # Example data from &quot;Democracy Does Cause Growth&quot; by Acemoglu, Naidu, Restrepo, and Robinson (2019)</code></pre>
<p><span class="math inline">\(~\)</span></p>
<div id="stage-1-constructing-matched-sets" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Stage 1: Constructing matched sets</h3>
<p>In the first stage, units that experience the treatment are matched with units that do not experience the treatment (control). This is practically an exact-match procedure, but relying only on the units’ treatment status over a user-specified length of time. This length of time is called <a href="definitions.html"><strong>L</strong></a> (short for Lags). If L = 0, units are matched solely on treatment status at time T, but this this would no longer be utilizing the time-dimension in the dataset.</p>
<p>In figure <a href="#fig:ExampleStage1">1.1</a> they illustrate an example with 5 units over 6 time periods, with L = 3. Values in the triangles and circles indicate whether this is a treated unit or a control unit, while the square box is the pre-treatment period, the length of which is defined by <a href="definitions.html"><strong>L</strong></a>. In creating matched sets, units with similar pre-treatment periods <em>across the exact same time periods T</em> but with unequal treatment status in the triangles/circles are matched together to compose a set. In the left-hand panel (a), we are looking for units we can use to find the <a href="definitions.html"><strong>ATT</strong></a>. The three red units and the three blue units compose separate matched sets with one treated unit and two control units. The grey units compose a third matched set with one treated unit and one control unit.</p>
<p>The right-hand panel (b) is similar, but now we are looking for sets with which we can analyse the <a href="definitions.html"><strong>ART</strong></a>. The blue circle in this panel simply illustrates a case of reversal but which do not have any suitable match in the data.</p>
<p>Any data point that does not enter into a matched set is discarded.</p>
<p><span class="math inline">\(~\)</span></p>
<div class="figure"><span style="display:block;" id="fig:ExampleStage1"></span>
<img src="Graphics/ajps12685-fig-0002-m.jpg" alt="" />
<p class="caption">Figure 1.1:  An Example of Matched Sets with Five Units and Six Time Periods and with L = 3</p>
</div>
<p><span class="math inline">\(~\)</span></p>
<p>The following R-code gives an overview of the <code>PanelMatch()</code>-arguments that refer to stage 1:</p>
<pre class="r"><code>mod &lt;- PanelMatch(
  
  #General information for the PanelMatch-function:
  data = dem, #Data to be used
  time.id = &quot;year&quot;, #Name of time-column 
  unit.id = &quot;wbcode2&quot;, #Name of unit-column
  treatment = &quot;dem&quot;, #Name of treatment variable
  outcome.var = &quot;y&quot;, #Name of outcome variable (they have named the column Y...lol...)
  qoi = &quot;att&quot;, #Quantity of interest.
  verbose = TRUE, #Prints more information about all calculations
  
  #    Arguments for Stage 1:
  matching = TRUE, #Should Stage 1 exact match on treatment history?
  lag = 4, # This argument controls the number of lags, notated as &quot;L&quot; int he article
  match.missing = FALSE, # Should patterns of missingness be included in matching the units into sets?
  listwise.delete = TRUE, #Delete missingness listwise
  exact.match.variables = NULL, #In principle, the exact matching in stage 1 can include all categorical variables, not just the treatment history. Character vector of relevant categorical variables can be added here. NULL means that we will only match on treatment history.
  
  ...
  
)</code></pre>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="stage-2-refine-match-sets" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Stage 2: Refine match sets</h3>
<p>In stage 2 the goal is to establish balance on time-varying covariates within these matched sets over the pre-treatment period (<a href="definitions.html"><strong>L</strong></a>). This is to address the <a href="definitions.html"><strong>parallel trends assumption</strong></a>. This can be done with many existing approaches, and the article suggests either using a matching procedure such as Mahalanobis distance or Propensity matching, or create unit weights.</p>
<p>In the evaluations in the article, weighting performs better, and at times a lot better, than distance matching.</p>
<div id="distance-balancing" class="section level4" number="1.2.2.1">
<h4><span class="header-section-number">1.2.2.1</span> Distance-balancing</h4>
<p><em>Using Mahalanobis-distance:</em> Computes standardized Mahalanobis-distance between the treated unit and each of its matched control units, averaged over the pre-treatment period.</p>
<p><em>Propensity score matching:</em> Estimates the conditional probability that a unit will experience the treatment given pre-treatmeant covariates (the propensity score). This approach requires additional specification for how to estimate the probability of being treated, such as a logistic regression.</p>
<p>Once a distance measure has been selected and computed, the sample is reduced to the <strong>J</strong> most similar units within each matched set.</p>
</div>
<div id="weight-balancing" class="section level4" number="1.2.2.2">
<h4><span class="header-section-number">1.2.2.2</span> Weight-balancing</h4>
<p>Each control unit within each matched set is assigned a weight, with greater weight assigned to more similar units. This approach requires the user to select some method to determine similarity. The authors suggest <a href="https://onlinelibrary.wiley.com/doi/10.1111/1468-0262.00442">propensity score weighting</a> or calibration weights.</p>
<p><span class="math inline">\(~\)</span></p>
<p>The following R-code gives an overview of the <code>PanelMatch()</code>-arguments that refer to stage 2:</p>
<pre class="r"><code>mod &lt;- PanelMatch(
  
  #General information for the PanelMatch-function:
  data = dem, #Data to be used
  time.id = &quot;year&quot;, #Name of time-column 
  unit.id = &quot;wbcode2&quot;, #Name of unit-column
  treatment = &quot;dem&quot;, #Name of treatment variable
  outcome.var = &quot;y&quot;, #Name of outcome variable (they have named the column Y...lol...)
  qoi = &quot;att&quot;, #Quantity of interest.
  verbose = TRUE, #Prints more information about all calculations
  
  #    Arguments for Stage 1:
  ...
  
  #    Arguments referring to Stage 2:
  lead = 0:4, #How far (years) into the future should the outcome be measured? Notated as F in the article
  forbid.treatment.reversal = FALSE, #Should reversal be allowed in the period between the treatment occurs (T) and the outcome is measured (T + leads/F)
  refinement.method = &quot;CBPS.weight&quot;, #Covariate balancing propensity score weights from Imai and Ratkovic (2014)
  size.match = 5, #Indicates the J closest matches to keep in the refinement. This is only relevant for the distance-methods, not weight-methods.
  covs.formula = as.formula(~ I(lag(tradewb, 1:4)) + I(lag(y, 1:4)) #Formula for refinement
                            
  )</code></pre>
<p><span class="math inline">\(~\)</span></p>
</div>
</div>
<div id="stage-3-the-did-estimator" class="section level3" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> Stage 3: The DiD-estimator</h3>
<p>Before executing the DiD-estimator, the user needs to specify how long into the future the effect should occur, called <a href="definitions.html"><strong>F</strong></a>. If F = 2 and treatment occurs in T = 0, then the outcome Y from T+2 is used. This is similar to lagging the treatment variable in a normal regression setup, but with a lead-logic instead. Once F is specified, we can proceed with the DiD-estimator.</p>
<p>The DiD-estimator sequence: 1. Calculates the counterfactual outcome for each treated unit using the weighted average of the refined matched control units. 2. Computes DiD estimate of the ATT for each treated unit. 3. Averages the ATT estimates across all treated units.</p>
<p><span class="math inline">\(~\)</span></p>
<p>The following R-code first runs stage 1 and 2 with the <code>PanelMatch()</code>-function, then executes stage 3 using the <code>PanelEstimate</code>-function. It also produces a simply visualization of the result:</p>
<p><span class="math inline">\(~\)</span></p>
<pre class="r"><code>      mod &lt;- PanelMatch(
        
        #General information for the PanelMatch-function:
        data = dem, #Data to be used
        time.id = &quot;year&quot;, #Name of time-column 
        unit.id = &quot;wbcode2&quot;, #Name of unit-column
        treatment = &quot;dem&quot;, #Name of treatment variable
        outcome.var = &quot;y&quot;, #Name of outcome variable (they have named the column Y...lol...)
        qoi = &quot;att&quot;, #Quantity of interest.
        verbose = TRUE, #Prints more information about all calculations
        
        #    Arguments for Stage 1:
        matching = TRUE, #Should Stage 1 exact match on treatment history?
        lag = 4, # This argument controls the number of lags, notated as &quot;L&quot; int he article
        match.missing = FALSE, # Should patterns of missingness be included in matching the units into sets?
        listwise.delete = TRUE, #Delete missingness listwise
        exact.match.variables = NULL, #In principle, the exact matching in stage 1 can include all categorical variables, not just the treatment history. Character vector of relevant categorical variables can be added here. NULL means that we will only match on treatment history.
        
        #    Arguments referring to Stage 2:
        lead = 0:4, #How far (years) into the future should the outcome be measured? Notated as F in the article
        forbid.treatment.reversal = FALSE, #Should reversal be allowed in the period between the treatment occurs (T) and the outcome is measured (T + leads/F)
        refinement.method = &quot;CBPS.weight&quot;, #Covariate balancing propensity score weights from Imai and Ratkovic (2014)
        size.match = 5, #Indicates the J closest matches to keep in the refinement. This is only relevant for the distance-methods, not weight-methods.
        covs.formula = as.formula(~ I(lag(tradewb, 1:4)) + I(lag(y, 1:4)) ) #Formula for refinement
        
      )
      
      #Stage 3
      res &lt;- PanelEstimate(sets = mod, data = dem)
      
      #Simple visualization of the result
      plot(res)</code></pre>
<p><img src="solutions_files/figure-html/FullFunction-1.png" width="672" />
<span class="math inline">\(~\)</span></p>
</div>
<div id="extensions" class="section level3" number="1.2.4">
<h3><span class="header-section-number">1.2.4</span> Extensions</h3>
<p>Step 1 of the <code>PanelMatch()</code>-approach is intuitive and rather straight-forward. While it is currently not implemented in the <code>R</code>-package, one the initial matching and balancing has been done, we could estimate the ATT with Poisson, logit, or other distributions.</p>
</div>
</div>
<div id="unsolved-problems" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Unsolved problems</h2>
<ul>
<li>Requires binary treatment</li>
</ul>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="list-of-assumptions" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> List of assumptions</h2>
<ul>
<li><p>Parallel trends</p></li>
<li><p>Assumed causal order: Confounders Z are realized before treatment X is realized before outcome Y</p></li>
<li><p>Assumes absence of between-unit spillover effects (they are looking into applications without this assumption)</p></li>
</ul>
<p>–</p>
</div>
</div>
<div id="wooldridge" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Wooldridge 2021</h1>
<p><a href="https://www.researchgate.net/publication/353938385_Two-Way_Fixed_Effects_the_Two-Way_Mundlak_Regression_and_Difference-in-Differences_Estimators">“Two-Way Fixed Effects, the Two-Way Mundlak Regression, and Difference-in-Differences Estimators” by Wooldridge, Jeffrey M. (2021)</a></p>
<p>Wooldridge’s <a href="https://t.co/q1AnkhEF97">Dropbox folder</a> (Contains Stata-code)</p>
<p><a href="https://twitter.com/jmwooldridge/status/1427472491367305219">The Tweet</a></p>
<div id="the-problem-it-solves-1" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> The problem it solves</h2>
<p>Wooldridge shows in this article that the issue with staggered intervention and heterogeneous treatment effects can be solved by altering the parameterization of the linear regression model. He also shows that you can get similar results both using TWFE or a pooled model where group level averages are included into the model (the Two-Way Mundlak model). The benefit with the latter approach is that it is easily adapted to non-linear models such as exponential, logit, and probit models. This idea is further elaborated in another article: <a href="https://www.researchgate.net/publication/362532821_Simple_Approaches_to_Nonlinear_Difference-in-Differences_with_Panel_Data">“Simple Approaches to Nonlinear Difference-in-Differences with Panel Data”</a>. Wooldridge has also recorded a <a href="https://www.dropbox.com/sh/zj91darudf2fica/AADj_jaf5ZuS1muobgsnxS6Za?dl=0&amp;preview=did_seminar_20210923.mp4">“lecture on this topic”</a> (link to his shared Dropbox folder). The introduction to <a href="https://www.dropbox.com/sh/zj91darudf2fica/AADWlJIH9SI3XvtADXgYma0ka/ESTIMATE_DiD?dl=0&amp;preview=ESTIMATE_TRF_0.mp4&amp;subfolder_nav_tracking=1">“Potential Outcomes, Treatment Effects, and Estimation Methods”</a> also comes highly recommended.</p>
</div>
<div id="the-way-it-solves-it-1" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> The way it solves it</h2>
<p><span class="math inline">\(d_i\)</span>: Are you eventually treated?</p>
<p><span class="math inline">\(p_t\)</span>: Are we in a post-treatment period?</p>
<p><span class="math display">\[w_i = d_i \cdot p_t\]</span></p>
<p><span class="math display">\[y_{it} = \alpha + \beta w_i + d_i + p_t + u_{it}\]</span></p>
<blockquote>
<p>You are not doing anything fancy. [[<a href="https://www.dropbox.com/sh/zj91darudf2fica/AADj_jaf5ZuS1muobgsnxS6Za?dl=0&amp;preview=did_seminar_20210923.mp4" class="uri">https://www.dropbox.com/sh/zj91darudf2fica/AADj_jaf5ZuS1muobgsnxS6Za?dl=0&amp;preview=did_seminar_20210923.mp4</a>| Wooldridge in DiD seminar 23.09.21]]</p>
</blockquote>
<p>Wooldridge shows that the TWFE estimator is equivalent to the “pooled” regression which is exactly the difference-in-differences estimator (difference before and after treatment for the treated group versus before after for the control group).</p>
<p><strong>So what happens when we have heterogeneous effects in a staggered treatment setting?</strong></p>
<blockquote>
<p>It is not a problem with our estimator. It is a problem with our imagination. (Wooldridge)</p>
</blockquote>
<p>Wooldridge notes that <span class="math inline">\(w_i \cdot fr_t = d_i \cdot fr_t\)</span> : Interacting the treatment indicator with the time-dummies is the same as interacting the time-constant <span class="math inline">\(d_i\)</span> with the time-dummies <span class="math inline">\(fr_t\)</span>. The model he comes up with for correct parameterization of the case with staggered treatments and heterogeneous treatment effects is the following:</p>
<p><span class="math display">\[Y_{it} = \alpha + \beta_q (w_{it} \cdot fq_t) + ... + \beta_T (w_{it} \cdot fT_t) + \xi d_i + \theta_q fq_t + ... + \theta_T fT_t + u_{it},\]</span></p>
<p><span class="math display">\[t = 1, ..., T; i = 1,2,...,N\]</span></p>
<p><span class="math inline">\(fq_t ... fT_t\)</span> denote the fact that we are in a staggered treatment setting and that different cohorts have different pre- and post-treatment periods. <span class="math inline">\(q\)</span> is the first period someone enters treatment. We could add dummies for time <span class="math inline">\(t &lt; q\)</span>, but these are redundant.</p>
<p>In the above equation, we allow treatment effects <span class="math inline">\(\beta_{q ... T}\)</span> to change over treatment period. Below, we show how we can simply specify this model in R (including several redundant parameters).</p>
<pre class="r"><code>set.seed(100)

df &lt;- did2s::gen_data(
  g1 = 2011, # treatment date for group 1
  g2 = 2012, # treatment date for group 2
  g3 = 0, # treatment date for group 3
  panel = c(2010, 2012), # start and end years for panel
  te1 = 3, # treatment effect for group 1
  te2 = 1, # treatment effect for group 2
  te3 = 0, #  treatment effect for group 3
  te_m1 = 0, # treatment effect slope per year for group 1
  te_m2 = 0, # treatment effect slope per year for group 2
  te_m3 = 0, # treatment effect slope per year for group 3
  n = 1500 # number of individual in sample
)

df_hom &lt;- did2s::gen_data(panel = c(2010, 2012),
                          g1 = 2011, g2 = 2012, g3 = 0,
                          te1 = 2, te2 = 2, te3 = 0,
                          te_m1 = 0, te_m2 = 0, te_m3 = 0)
# df is a simulated dataset with heterogeneous and staggered treatment effects (the group treatd in 2011 has effect = 3, while the group treated one year later has effect = 1). A first-mover advantage is common in many real applications.
# df_hom is a simulated dataset with homogeneous and staggered treatment effects. Here, the expected (average) effect in both treatment cohorts are the same.

# Two-Way Fixed-Effects with homogeneous treatment effects
feols(dep_var ~ treat | unit + year, data = df_hom, cluster = &quot;state&quot;) |&gt; summary()

# Two-Way Mundlak with homogeneous treatment effects
df_hom &lt;- df_hom |&gt; 
  group_by(unit) |&gt; mutate(mtreat_u = mean(treat)) |&gt; 
  group_by(year) |&gt; mutate(mtreat_t = mean(treat))
lm(dep_var ~ treat + mtreat_u + mtreat_t, data = df_hom) |&gt; summary()

# This follows an equivalent logic, note that year dummies t &lt; q are redundant
feols(dep_var ~ treat | year + g, data = df_hom) |&gt; summary()

# So far, everything is good (although almost by coincidence, as we were lucky that the effect for the two cohorts were exactly the same!)

# The naive Two-Way Mundlak and TWFE is wrongly parameterized when we have heterogeneous TEs.
# This produces an average effect, but not 3 for group 1 and 1 for group 2.
df &lt;- df |&gt; 
  group_by(unit) |&gt; mutate(mtreat_u = mean(treat)) |&gt; 
  group_by(year) |&gt; mutate(mtreat_t = mean(treat))

lm(dep_var ~ treat + mtreat_u + mtreat_t, data = df) |&gt; summary()

# Similarly wrong
feols(dep_var ~ treat | year + g, data = df) |&gt; summary()

# Instead, we can add interactions between treatment cohort (g) and time-since treatment (rel_year)
# Note that more than one level for rel_year t &lt; q is redundant, and we could have collapsed these.
# This we could have done for year t &lt; q too if we wanted.
# Note that we need to provide correct base-line comparisons to get correctly formed estimates.
levels(factor(df$rel_year))
feols(dep_var ~  factor(g):factor(rel_year) | year , data = df) |&gt; summary()
# Adding the treatment indicator is also redundant
feols(dep_var ~ treat : factor(g) : factor(rel_year) | year , data = df) |&gt; summary()

# Estimates for groups, calendar time, or &quot;event study&quot; (grouped by rel_year) can be aggregated from here
# An easier approach is to use specialized functions such as those in the did-package
did::att_gt(yname = &quot;dep_var&quot;, gname = &quot;g&quot;, idname = &quot;unit&quot;, tname = &quot;year&quot;, 
           control_group = &quot;notyettreated&quot;, data = df) |&gt; 
  did::aggte(type = &quot;group&quot;) 

# control_group could be restricted to &quot;nevertreated&quot;  
# type can also be &quot;dynamic&quot; (event study),  &quot;calendar&quot;, or &quot;simple&quot; (ATT)

# Compare the &quot;simple&quot; approach with the wrongly parameterized model to see the problem of using the naive TWFE/TWM to estimate the ATT</code></pre>
<p>One nice thing about the TWM is that it allows time-constant covariates <span class="math inline">\(X_i\)</span>. These are particularly useful if we include them as interactions with time dummies and treatment. <span class="math inline">\(X_i\)</span> would then become a mediator. Doing this would be a way to explore treatment heterogeneity across observed covariates. It should be mentioned here that the differences in estimated effects (e.g., across cohorts or across <span class="math inline">\(X_i\)</span>) are not causal estimates themselves. We would then need to consider the selection mechanism into cohorts or into different <span class="math inline">\(X_i\)</span>.</p>
<p>We have also not discussed the assumptions needed to interpret the estimate of the treatment as causal here, such as SUTVA, the parallel trends assumption, and the no anticipation assumption. In most observable settings, some or all of these assumptions are violated (to some degree). It is therefore always advisable to test the model in several ways, e.g., through a discussion of how the model relates to other things we belive is true, through testing the predictive capacity of the model, through building alternative explanations, etc. Furthermore, even if the causal estimate is correct, there are no guarantees that causal effects in the social context would stay the same over time or for other cases. Exploring treatment heterogeneity is also a way to build some intuition for how effects might change in new settings.</p>
</div>
<div id="an-example-implementation-of-twm-for-real-tscs-data-in-r" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> An example implementation of TWM for real TSCS data in R</h2>
<p>For applied researchers like ourselves, implementing Wooldridge’s TWM was not straight forward. Here, we give a step-by-step guide for how to setup the data and estimate the ATT, using the dataset from <a href="https://www.journals.uchicago.edu/doi/10.1086/700936">Acemoglu, Naidu, Restrepo and Robindson (2019)</a>. This is the same dataset used as an example for <code>PanelMatch()</code> above.</p>
<p>In doing this, we want the code to be able to accommodate all kinds of complexities: staggered adoption, treatment reversal, heterogeneous treatment effects, and the presence of never-treated and always-treated units.</p>
<pre class="r"><code>library(PanelMatch)
data(dem)</code></pre>
<p>The dataset comes as a common country-year long-format table. The variables of interest for us is the unit ID (<code>wbcode2</code>), year (<code>year</code>), and whether or not country <code>i</code> is a democracy (<code>dem</code>) at time <code>t</code>. We need some more stuff:</p>
<ol style="list-style-type: decimal">
<li>A time-until/since-treatment-occurred variable, with separate categories from always- and never-treated</li>
<li>Cohort dummies that identifies:
<ul>
<li>units that are treated in the same year</li>
<li>units that were already treated when time-series started</li>
<li>units that are never treated</li>
</ul></li>
<li>Deal with reversal, by one of two ways:
<ul>
<li>Delete all years for a unit from the year it reverses, or</li>
<li>Separate units into multiple spells, with a new spell created for a unit each time it reverses to non-treated status
<ul>
<li><strong><em>NOTE:</em></strong> Separating units into multiple spells at reversal is not something Wooldridge suggests, but we do not see any reason why it shouldn’t work. We can cluster the standard errors by country (and not country-spell) to deal with non-independent error terms.</li>
</ul></li>
</ul></li>
</ol>
<p>To get the list of items above, we first need to identify whether and in what year a unit is treated. We can do this by simply comparing democracy status in t with t-1. But in doing this, we need to fix another complication: We can’t have missing data, as this will ruin later code. When lagging, we will have missing data in the first year. If you are willing to assume that treatment-status did not change in the first year, you can simply assign the same status code to democracy in t-1 is it has in t.</p>
<pre class="r"><code>#####     Goal 1: Identify when a unit is treated
#Lag dem by 1 to identify when change occurs
dem &lt;- dem[order(dem$wbcode2, dem$year),] #Order before lag
dem &lt;- dem %&gt;% group_by(wbcode2) %&gt;% mutate(dem_lag1 = lag(dem))

#We can&#39;t have missing data, as this will ruin later code. But if you are willing to assume that treatment-status did not change in the first year, you can run this code
dem$dem_lag1 &lt;- ifelse(is.na(dem$dem_lag1)==TRUE, dem$dem,
                       dem$dem_lag1) #Assume that treatment status was equal to first year</code></pre>
<p>We still need to remove rows with missing information on our treatment (<code>dem</code>). A word of caution: Make sure that this does not delete time-series in the middle of a country’s history, only at start or end. You must avoid this:</p>
<pre class="r"><code>error_example &lt;- data.frame(&quot;ID&quot; = 1,
                            &quot;year&quot; = 1970:1973,
                            &quot;dem_lag1&quot; = c(1, NA, NA, 1))

knitr::kable(error_example)</code></pre>
<p>You can diagnose whether this is a problem. If this code returns any FALSE, you need to inspect:</p>
<pre class="r"><code>table(dem %&gt;% subset(is.na(dem_lag1)==FALSE) %&gt;%
        group_by(wbcode2) %&gt;%
        mutate(duration_since_last_year = 1==(year - lag(year, 1)) ) %&gt;% ungroup() %&gt;%
        select(duration_since_last_year))</code></pre>
<p>Once this is corrected, you can delete rows:</p>
<pre class="r"><code>###     If diagnose is ok, you can delete rows
dem &lt;- dem[which(is.na(dem$dem_lag1)==FALSE),]</code></pre>
<p>Now you can identify change in treatment-status. Here we create the variable <code>change_in_dem</code>, which can have the values -1 (reversal), 0 (status quo), and 1 (treated).</p>
<pre class="r"><code>###     Identify change in treatment status
dem$change_in_dem &lt;- dem$dem - dem$dem_lag1 #change_in_dem can now take the values -1 (reversal), 0 (status quo), and 1 (treated)</code></pre>
<p>Now we wncounter point 4 above: How should we deal with reversal? We start by identifying the occurrences of reversal, and assign unit-spell IDs, so that each unit has a new ID for each time it reverses:</p>
<pre class="r"><code>#####     Deal with reversal
###     If you want to include the same country multiple times, it must be considered a new unit each time it reverses back to none-treated status:
dem$reversal &lt;- ifelse(dem$change_in_dem &lt; 0, 1, 0)
dem &lt;- dem %&gt;% group_by(wbcode2) %&gt;% mutate(spell = cumsum(reversal)) #Count number of reversals
dem$unit_spell_id &lt;- paste0(dem$wbcode2, &quot;_&quot;, dem$spell) #By combining unit-id with number of reversals, we now have a unit-spell-ID.</code></pre>
<p>If you want to go with solution 1 to the reversal problem, to simply delete all country-years once a country reverses, run the following code. If you want to keep countries as separate units after each reversal, do not run the following code.</p>
<pre class="r"><code>#If you want to delete everything after reversal, do this:
dem &lt;- dem[which(dem$spell&lt;1),]</code></pre>
<p>Right, 1/3 points dealt with. We now continue on to identify when treatment occurs for a unit, and then assign all units to a cohort dependeing on when treatment occurred:</p>
<pre class="r"><code>#####     Identify points in time where treatment occurs
dem$treated_this_year &lt;- ifelse(dem$change_in_dem &lt; 0, 0, dem$change_in_dem) #Converts -1 to 0


#####     Identify cohort
dem &lt;- dem[order(dem$unit_spell_id, dem$year), ]
tmp_cohortdat  &lt;- dem[which(dem$treated_this_year==1), c(&quot;unit_spell_id&quot;, &quot;year&quot;)]
tmp_cohortdat  &lt;- tmp_cohortdat %&gt;% rename(cohort = year) #Units will now be given cohort ID equal to the year they were treated
dem &lt;- full_join(dem, tmp_cohortdat)
rm(tmp_cohortdat)</code></pre>
<p>The keen eye will notice that the above code does not assign any cohort to never-treated and always-treated units, because <code>treated_this_year</code> is always 0 for these units. This is because we want to create a time-until/since-treatment-occurred (point 2 above) before we do this. This is easier to do when we can treat <code>cohort</code> as a numeric variable, which we can’t once we assign cohorts to never-treated and always-treated (they do not have any meaningful treatment-year).</p>
<p>Here, we create <code>time_to_traetment</code>, which is our time-until/since-treatment-occurred-variable.</p>
<pre class="r"><code>###     Create relative-time-to-treatment: (we need to adjust this later but easier to create while we can keep &quot;cohort&quot; numeric)
dem$time_to_treatment &lt;- dem$year-dem$cohort #This is easier to create while we can have cohort numeric (which we can&#39;t once we give a cohort to never- and always-treated)</code></pre>
<p>We can now assign cohort to always- and never- treated units:</p>
<pre class="r"><code>###     Give cohort to always- and never-treated
dem &lt;- dem %&gt;% mutate(cohort = ifelse(is.na(cohort)==TRUE &amp; dem==1, &quot;always_treated&quot;,
                                       ifelse(is.na(cohort)==TRUE &amp; dem==0, &quot;never_treated&quot;, as.character(cohort) ) ) )</code></pre>
<p>And we also need to give values to always- and never-treated units on the <code>time_to_treatment</code>-variable.</p>
<pre class="r"><code>###     Give relative-time also to never- and always- treated
dem$time_to_treatment &lt;- ifelse(dem$cohort == &quot;never_treated&quot;, &quot;Infinity&quot;,
                                ifelse(dem$cohort == &quot;always_treated&quot;, &quot;-Infinity&quot;, as.character(dem$time_to_treatment)
                                ))</code></pre>
<p>This is some obsolete code that we don’t think is needed, but it creates Wooldridge’s <em>w</em>:</p>
<pre class="r"><code>###     Indicate if unit will ever be (or always was) treated
dem$eventually_treated &lt;- ifelse(dem$cohort==&quot;never_treated&quot;, 0, 1) #This code is probably obsolete but not really sure. Useful to produce Wooldridge&#39;s w-variable. 

#####     Create the Wooldridge&#39;s w
dem$w &lt;- dem$eventually_treated * dem$dem #w_i_t = d_i * p_t = (will unit be treated) * (are you in post-treatment-period)</code></pre>
<p>And we have solved all points on our list. We can now get all sorts of estimates with simple regression. The power of the Mundlak-approach is that it flexible for different distributions, e.g. gaussian, poisson, logit etc.</p>
<p>Here, we estimate the cohor-specific ATT, and show that it is quite dramatically heterogeneous:</p>
<pre class="r"><code>#####   Estimate ATT
mod &lt;- feols(y ~ factor(cohort) : factor(time_to_treatment) | year , data = dem, cluster = ~wbcode2)
#####     Graph
mod &lt;- tidy(mod, conf.int = TRUE)

###   Clean term to get the useful information
mod$cohort &lt;- gsub(&quot;.*cohort.(.*):factor.*&quot;, &quot;\\1&quot;, mod$term)
mod$time_to_treatment &lt;- as.numeric(gsub(&quot;.*time_to_treatment.(.*)$&quot;, &quot;\\1&quot;, mod$term))

### Remove always-treated from plot
mod &lt;- mod %&gt;% subset(time_to_treatment&gt;-Inf)

### Plot
ggplot(mod, aes(y = estimate, ymin = conf.low, ymax = conf.high, x = time_to_treatment, fill=cohort)) +
  geom_line() +
  geom_ribbon(alpha = 0.5) +
  geom_vline(xintercept = 0) +
  theme_minimal()</code></pre>
<p><img src="solutions_files/figure-html/twm_att_heteroplot-1.png" width="2304" /></p>
<p>Lots of heterogeneity, but is there a signal in there somewhere? We can get the mean for each point in <code>time_to_treatment</code>, which shows the clear effect of democracy on GDP:</p>
<pre class="r"><code>mean_mod &lt;- mod %&gt;% group_by(time_to_treatment) %&gt;% mutate(mean_est = mean(estimate),
                                                           mean_max = mean(conf.high),
                                                           mean_low = mean(conf.low))
ggplot(mean_mod, aes(x = time_to_treatment, y = mean_est, ymax = mean_max, ymin = mean_low)) +
  geom_ribbon(alpha = 0.7) +
  geom_line() +
  geom_vline(xintercept = 0) +
  theme_minimal()</code></pre>
<p><img src="solutions_files/figure-html/twm_time_average-1.png" width="2304" /></p>
<div id="extensions-1" class="section level3" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Extensions</h3>
<p>There are various non-parametric alteration we could make to the data. For example, we could restrict it to only include a certain number of years before and after treatment occurs. We could add a quarantine period for observations after treatment reverses, if we want units to be able to re-enter the dataset after reversal, but not right away.</p>
<hr />
</div>
</div>
</div>
<div id="callaway-and-santanna-2021" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Callaway and Sant’Anna 2021</h1>
<p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0304407620303948">“Difference-in-Differences with Multiple Time Periods” by Callaway, Brantly and Sant’Anna, Pedro H. C. (2021)</a></p>
<div id="the-problem-it-solves-2" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> The problem it solves</h2>
<p>Callaway and Sant’Anna provide a way to estimate the ATT under staggered treatment and heterogeneous treatment effects. The <a href="https://cran.r-project.org/web/packages/did/vignettes/did-basics.html">did</a> R-package includes a simple to use approach to correctly estimate the group-time average treatment effects. Also see the <a href="https://bcallaway11.github.io/did/">did webpage</a> for more information.</p>
</div>
<div id="the-way-it-solves-it-2" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> The way it solves it</h2>
<p>By avoiding bad control groups (e.g., comparing treated units with already treated units, or if one thinks that the never-treated group is different from the group that eventually becomes treated, one can also only use the not yet treated group as control). Provides ways to aggregate the treatment effects into group-time treatment effects, the average group-level treatment effect, or the average effect of participating in treatment for groups that have been exposed to treatment exactly <span class="math inline">\(n\)</span> time periods. The default approach is a parametric doubly robust approach (using both inverse probability weighting and regression estimators). See <a href="https://www.dropbox.com/sh/zj91darudf2fica/AADWlJIH9SI3XvtADXgYma0ka/ESTIMATE_DiD?dl=0&amp;preview=ESTIMATE_TRF_0.mp4&amp;subfolder_nav_tracking=1">“Potential Outcomes, Treatment Effects, and Estimation Methods”</a> for an explanation of what “doubly robust” means (at the end of the lecture).</p>
<p>This code implements the method:</p>
<pre class="r"><code>    source(&quot;Data/generate_panel_data.R&quot;) #Generate random data

    out &lt;- att_gt(yname = &quot;y&quot;,
    gname = &quot;first_treat&quot;,
    idname = &quot;id&quot;,
    tname = &quot;time&quot;,
    xformla = ~1,
    data = dat,
    est_method = &quot;reg&quot;,
    control_group = &quot;notyettreated&quot; #Will include units that will receive treatment later as control group
    )
    
    #Plot
    ggdid(out, ylim = c(-.25,.1))</code></pre>
<p><img src="solutions_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>    #Event-type plot
    es &lt;- aggte(out, type = &quot;dynamic&quot;)
    ggdid(es)</code></pre>
<p><img src="solutions_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<p>Event-study plot:</p>
<pre class="r"><code>    #Event-type plot
    es &lt;- aggte(out, type = &quot;dynamic&quot;)
    ggdid(es)</code></pre>
<p><img src="solutions_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
